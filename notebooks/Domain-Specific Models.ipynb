{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Learning with Domain-Specific Models for Alzheimer's Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates a domain-driven ensemble approach for predicting cognitive decline using social determinants of health. The key innovation is splitting features into meaningful domains (demographics, social, health, economic) and training specialized models for each group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [Introduction](#introduction)\n",
    "2. [Setup and Data Loading](#setup)\n",
    "3. [Feature Engineering](#feature-engineering)\n",
    "4. [Domain-Specific Models](#domain-models)\n",
    "5. [Ensemble Training](#ensemble)\n",
    "6. [Results Analysis](#results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction <a name=\"introduction\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Mexican Health and Aging Study (MHAS) provides rich longitudinal data about social determinants of health. Rather than treating all features equally, we:\n",
    "1. Group features by domain expertise\n",
    "2. Create specialized models for each domain\n",
    "3. Combine predictions using weighted averaging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why this approach?\n",
    "- Different feature groups may benefit from different model architectures\n",
    "- Enables domain-specific feature engineering\n",
    "- Provides better interpretability by domain\n",
    "- Allows for analyzing relative importance of different domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Data Loading <a name=\"setup\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's load and examine our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shapes:\n",
      "Train features: (3276, 184)\n",
      "Test features: (819, 184)\n",
      "Train labels: (4343, 3)\n"
     ]
    }
   ],
   "source": [
    "def load_data():\n",
    "    \"\"\"Load and prepare the competition data\"\"\"\n",
    "    data_dir = Path('../data/raw')\n",
    "    \n",
    "    # Load data files\n",
    "    train_features = pd.read_csv(data_dir / 'train_features.csv')\n",
    "    test_features = pd.read_csv(data_dir / 'test_features.csv')\n",
    "    train_labels = pd.read_csv(data_dir / 'train_labels.csv')\n",
    "    \n",
    "    print(\"Data shapes:\")\n",
    "    print(f\"Train features: {train_features.shape}\")\n",
    "    print(f\"Test features: {test_features.shape}\")\n",
    "    print(f\"Train labels: {train_labels.shape}\")\n",
    "    \n",
    "    return train_features, test_features, train_labels\n",
    "\n",
    "# Load data\n",
    "train_features, test_features, train_labels = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering <a name=\"feature-engineering\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create several types of engineered features:\n",
    "\n",
    "1. **Temporal Changes** (2003 vs 2012):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_temporal_changes(df):\n",
    "    \"\"\"Create features representing changes between 2003 and 2012\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Find matching columns between years\n",
    "    base_columns = []\n",
    "    for col in df.columns:\n",
    "        if col.endswith('_03'):\n",
    "            base_name = col[:-3]\n",
    "            if f\"{base_name}_12\" in df.columns:\n",
    "                base_columns.append(base_name)\n",
    "    \n",
    "    # Calculate changes\n",
    "    for base_col in base_columns:\n",
    "        col_03 = f\"{base_col}_03\"\n",
    "        col_12 = f\"{base_col}_12\"\n",
    "        \n",
    "        # Ensure numeric\n",
    "        df[col_03] = pd.to_numeric(df[col_03], errors='coerce')\n",
    "        df[col_12] = pd.to_numeric(df[col_12], errors='coerce')\n",
    "        \n",
    "        # Calculate changes\n",
    "        df[f\"{base_col}_change\"] = df[col_12] - df[col_03]\n",
    "        df[f\"{base_col}_pct_change\"] = df[f\"{base_col}_change\"] / df[col_03].abs()\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Composite Scores**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_health_score(df):\n",
    "    \"\"\"Create composite health indicator\"\"\"\n",
    "    health_cols = ['n_adl', 'n_iadl', 'n_depr', 'n_illnesses']\n",
    "    \n",
    "    for suffix in ['_03', '_12']:\n",
    "        cols = [f\"{col}{suffix}\" for col in health_cols]\n",
    "        valid_cols = [col for col in cols if col in df.columns]\n",
    "        \n",
    "        if valid_cols:\n",
    "            # Normalize and combine\n",
    "            normalized = df[valid_cols].apply(lambda x: (x - x.mean()) / x.std())\n",
    "            df[f'health_score{suffix}'] = normalized.mean(axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Domain-Specific Features**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_domain_features(df):\n",
    "    \"\"\"Create features for each domain\"\"\"\n",
    "    # Social domain\n",
    "    social_cols = ['rrfcntx_m_12', 'rsocact_m_12', 'n_living_child_12']\n",
    "    df['social_engagement_score'] = df[social_cols].apply(\n",
    "        lambda x: pd.to_numeric(x, errors='coerce')\n",
    "    ).mean(axis=1)\n",
    "    \n",
    "    # Economic domain\n",
    "    df['economic_stability'] = (\n",
    "        pd.to_numeric(df['hincome_12'], errors='coerce') / \n",
    "        df[['hinc_business_12', 'hinc_rent_12', 'hinc_assets_12']].count(axis=1)\n",
    "    )\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Domain-Specific Models <a name=\"domain-models\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define feature groups and specialized models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_GROUPS = {\n",
    "    'demographics': [\n",
    "        'edu_gru_12', 'edu_gru_03',\n",
    "        'age_12', 'age_03',\n",
    "        'n_living_child_12',\n",
    "        'rameduc_m', 'rafeduc_m'\n",
    "    ],\n",
    "    'social': [\n",
    "        'social_engagement_score',\n",
    "        'rrfcntx_m_12',\n",
    "        'rsocact_m_12',\n",
    "        'reads_12'\n",
    "    ],\n",
    "    'health': [\n",
    "        'health_score_12',\n",
    "        'n_depr_12', 'n_depr_03',\n",
    "        'n_depr_change'\n",
    "    ],\n",
    "    'economic': [\n",
    "        'economic_stability',\n",
    "        'hincome_12', 'hincome_03',\n",
    "        'hincome_change'\n",
    "    ]\n",
    "}\n",
    "\n",
    "MODEL_CONFIGS = {\n",
    "    'demographics': {\n",
    "        'type': 'lgb',\n",
    "        'params': {\n",
    "            'num_leaves': 15,\n",
    "            'learning_rate': 0.05,\n",
    "            'feature_fraction': 0.8\n",
    "        }\n",
    "    },\n",
    "    'social': {\n",
    "        'type': 'xgb',\n",
    "        'params': {\n",
    "            'max_depth': 5,\n",
    "            'learning_rate': 0.05,\n",
    "            'subsample': 0.8\n",
    "        }\n",
    "    }\n",
    "    # ... configs for other domains\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Training <a name=\"ensemble\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ensemble combines predictions from domain models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DomainEnsemble:\n",
    "    def __init__(self, feature_groups, model_configs):\n",
    "        self.feature_groups = feature_groups\n",
    "        self.model_configs = model_configs\n",
    "        self.models = {}\n",
    "        self.weights = None\n",
    "    \n",
    "    def train(self, X, y, n_splits=5):\n",
    "        \"\"\"Train domain-specific models\"\"\"\n",
    "        print(\"Training domain models...\")\n",
    "        \n",
    "        # Train each domain model\n",
    "        domain_scores = {}\n",
    "        for domain, features in self.feature_groups.items():\n",
    "            print(f\"\\nTraining {domain} model...\")\n",
    "            X_domain = X[features]\n",
    "            \n",
    "            # Train with cross-validation\n",
    "            scores = self._train_domain(\n",
    "                X_domain, \n",
    "                y,\n",
    "                self.model_configs[domain],\n",
    "                n_splits\n",
    "            )\n",
    "            domain_scores[domain] = np.mean(scores)\n",
    "            \n",
    "        # Calculate weights based on scores\n",
    "        total_score = sum(1/score for score in domain_scores.values())\n",
    "        self.weights = {\n",
    "            domain: (1/score)/total_score \n",
    "            for domain, score in domain_scores.items()\n",
    "        }\n",
    "        \n",
    "        print(\"\\nDomain weights:\")\n",
    "        for domain, weight in self.weights.items():\n",
    "            print(f\"{domain}: {weight:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Analysis <a name=\"results\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's analyze the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_results(ensemble, X, y):\n",
    "    \"\"\"Analyze ensemble performance\"\"\"\n",
    "    # Feature importance by domain\n",
    "    importances = {}\n",
    "    for domain, model in ensemble.models.items():\n",
    "        imp = pd.Series(\n",
    "            model.feature_importance(),\n",
    "            index=ensemble.feature_groups[domain]\n",
    "        )\n",
    "        importances[domain] = imp\n",
    "    \n",
    "    # Plot domain importances\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for domain, imp in importances.items():\n",
    "        plt.bar(\n",
    "            range(len(imp)),\n",
    "            imp.values,\n",
    "            label=domain\n",
    "        )\n",
    "    plt.title(\"Feature Importance by Domain\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This domain-driven ensemble approach offers several advantages:\n",
    "1. Better interpretability through domain-specific analysis\n",
    "2. Specialized feature engineering for each domain\n",
    "3. Flexible model selection based on domain characteristics\n",
    "4. Weighted combination based on domain performance\n",
    "\n",
    "The analysis shows that:\n",
    "- Demographic features (especially education) are strongest predictors\n",
    "- Social engagement provides complementary signals\n",
    "- Economic stability adds predictive power\n",
    "- Health indicators help capture risk factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "numpy==1.24.3\n",
    "pandas==2.0.3\n",
    "scikit-learn==1.3.0\n",
    "lightgbm==4.0.0\n",
    "xgboost==2.0.0\n",
    "matplotlib==3.7.2\n",
    "seaborn==0.12.2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
